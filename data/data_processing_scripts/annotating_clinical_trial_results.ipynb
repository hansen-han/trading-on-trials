{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5250401e",
   "metadata": {},
   "source": [
    "# annotating_clinical_trial_results.ipynb\n",
    "The goal of this notebook is to extract additional features from clinical trial result press releases for further analysis / modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc92af7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import sqlite3\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from openai import OpenAI\n",
    "\n",
    "# Helper Functions\n",
    "def make_json_llm_call(client, prompt):\n",
    "    import json\n",
    "    open_ai_model = \"gpt-4o-mini\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "            ],\n",
    "            model=open_ai_model,\n",
    "            response_format={ \"type\": \"json_object\" }\n",
    "\n",
    "        )\n",
    "    json_str = chat_completion.choices[0].message.content\n",
    "    annotated_data = json.loads(json_str)\n",
    "    return annotated_data\n",
    "\n",
    "\n",
    "# fetch the mean close data of the 2 days before the event\n",
    "def get_two_days_before_event(financial_data, ticker, date_str):\n",
    "    # Get the DataFrame for the specific ticker\n",
    "    df = financial_data[ticker].copy()\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Convert the input string to a datetime object\n",
    "    event_date = datetime.strptime(date_str, \"%m_%d_%Y\")\n",
    "    \n",
    "    # Get all dates before the event\n",
    "    prior_dates = df.index[df.index < event_date]\n",
    "    \n",
    "    # Get the two most recent dates before the event\n",
    "    recent_dates = prior_dates.sort_values()[-2:]\n",
    "    \n",
    "    if len(recent_dates) < 2:\n",
    "        return f\"Not enough data before {event_date.date()} for ticker {ticker}\"\n",
    "    \n",
    "    return df.loc[recent_dates]\n",
    "\n",
    "def get_data_x_days_after_event(financial_data, ticker, date_str, range):\n",
    "    # Get the DataFrame for the specific ticker\n",
    "    df = financial_data[ticker].copy()\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Convert the input string to a datetime object\n",
    "    event_date = datetime.strptime(date_str, \"%m_%d_%Y\")\n",
    "    \n",
    "    # Get all dates after the event\n",
    "    future_dates = df.index[df.index > event_date]\n",
    "    \n",
    "    # Get the two earliest dates after the event\n",
    "    upcoming_dates = future_dates.sort_values()[:range]\n",
    "    \n",
    "    if len(upcoming_dates) < range:\n",
    "        return f\"Not enough data after {event_date.date()} for ticker {ticker}\"\n",
    "    \n",
    "    return df.loc[upcoming_dates]\n",
    "\n",
    "def flatten_annotation(row):\n",
    "    ann = row['annotation_json']\n",
    "    \n",
    "    # Copy all top-level keys except 'epidemiology'\n",
    "    flat = {k: v for k, v in ann.items() if k != 'epidemiology'}\n",
    "    \n",
    "    # Handle epidemiology: sum of estimated_incidence across all conditions\n",
    "    epidemiology = ann.get('epidemiology', {})\n",
    "    total_incidence = sum(\n",
    "        v.get('estimated_incidence', 0) \n",
    "        for v in epidemiology.values()\n",
    "        if isinstance(v, dict)\n",
    "    )\n",
    "    flat['total_estimated_incidence'] = total_incidence\n",
    "    \n",
    "    return pd.Series(flat)\n",
    "\n",
    "\n",
    "def get_volatility_and_price_change(financial_data, ticker, date_str):\n",
    "    # Get the DataFrame for the specific ticker\n",
    "    df = financial_data[ticker].copy()\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Convert the input string to a datetime object\n",
    "    event_date = datetime.strptime(date_str, \"%m_%d_%Y\")\n",
    "    \n",
    "    # Define the range: from 60 days before the event up to 2 days before\n",
    "    end_date = event_date - timedelta(days=2)\n",
    "    start_date = event_date - timedelta(days=60)\n",
    "    \n",
    "    # Filter the DataFrame for the desired period\n",
    "    mask = (df.index >= start_date) & (df.index <= end_date)\n",
    "    df_period = df.loc[mask]\n",
    "\n",
    "    if df_period.empty or df_period.shape[0] < 2:\n",
    "        return f\"Not enough data between {start_date.date()} and {end_date.date()} for ticker {ticker}\"\n",
    "\n",
    "    # Calculate daily returns\n",
    "    df_period['daily_return'] = df_period['Close'].pct_change()\n",
    "\n",
    "    # Calculate volatility (standard deviation of returns)\n",
    "    volatility = df_period['daily_return'].std()\n",
    "\n",
    "    # Calculate percent change from day -60 to day -2\n",
    "    price_start = df_period['Close'].iloc[0]\n",
    "    price_end = df_period['Close'].iloc[-1]\n",
    "\n",
    "    percent_change = float(((price_end - price_start) / price_start))\n",
    "\n",
    "    return {\n",
    "        \"volatility\": round(volatility, 3),\n",
    "        \"percent_change\": round(percent_change, 3)\n",
    "        # \"start_date\": df_period.index[0].date(),\n",
    "        # \"end_date\": df_period.index[-1].date(),\n",
    "        # \"df_period\": df_period\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"API_KEY\",  # this is also the default, it can be omitted\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7fb4e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = sqlite3.connect(\"biotech_data.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Enable returning rows as dictionaries (optional, but nice)\n",
    "conn.row_factory = sqlite3.Row\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "    SELECT \n",
    "        articles.id AS article_id,\n",
    "        article_annotation.annotation_json,\n",
    "        articles.date,\n",
    "        company.ticker\n",
    "    FROM article_annotation\n",
    "    JOIN articles ON article_annotation.article_id = articles.id\n",
    "    JOIN company ON articles.company_id = company.id\n",
    "''')\n",
    "\n",
    "\n",
    "# Fetch results\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Convert to list of dictionaries, parsing JSON field\n",
    "results = []\n",
    "for row in rows:\n",
    "    annotation = dict(row)\n",
    "    annotation[\"annotation_json\"] = json.loads(annotation[\"annotation_json\"])  # Convert JSON string to dict\n",
    "    results.append(annotation)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# what does the ticker distribution look like?\n",
    "\n",
    "# get tickers\n",
    "tickers = [item['ticker'] for item in results]\n",
    "\n",
    "# Count occurrences\n",
    "ticker_counts = Counter(tickers)\n",
    "ticker_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48dc654",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# download historical data for all companies\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "financial_data = {}\n",
    "start_date = \"2014-01-01\"\n",
    "end_date = \"2025-03-17\"  # Adjust as needed\n",
    "\n",
    "for ticker in tqdm(list(set(tickers))):\n",
    "    # Fetch historical data\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    # Keep only Open, High, Low, Close columns\n",
    "    stock_data = stock_data[['Open', 'High', 'Low', 'Close']]\n",
    "    financial_data[ticker] = stock_data\n",
    "\n",
    "\n",
    "# add the S&P 500 index as a reference\n",
    "stock_data = yf.download(\"SPY\", start=start_date, end=end_date)\n",
    "\n",
    "# Keep only Open, High, Low, Close columns\n",
    "stock_data = stock_data[['Open', 'High', 'Low', 'Close']]\n",
    "financial_data['SPY'] = stock_data\n",
    "\n",
    "\n",
    "# Assign small cap, mid cap, and large cap labels to each ticker\n",
    "ticker_market_cap = {}\n",
    "\n",
    "for ticker in tqdm(list(set(tickers))):\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        ticker_market_cap[ticker] = info['marketCap']\n",
    "    except:\n",
    "        print(\"error for:\", ticker)\n",
    "        pass\n",
    "\n",
    "def classify_market_caps(market_caps_dict):\n",
    "    cap_labels = {}\n",
    "    for ticker, cap in market_caps_dict.items():\n",
    "        if cap is None:\n",
    "            cap_labels[ticker] = \"Unknown\"\n",
    "        elif cap < 2e9:\n",
    "            cap_labels[ticker] = \"Small Cap\"\n",
    "        elif cap < 10e9:\n",
    "            cap_labels[ticker] = \"Mid Cap\"\n",
    "        else:\n",
    "            cap_labels[ticker] = \"Large Cap\"\n",
    "    return cap_labels\n",
    "\n",
    "\n",
    "cap_classes = classify_market_caps(ticker_market_cap)\n",
    "\n",
    "\n",
    "# how many tickers could we not fetch?\n",
    "tickers_with_data = list(financial_data.keys())\n",
    "count = 0\n",
    "for ticker in list(set(tickers)):\n",
    "    if ticker not in tickers_with_data:\n",
    "        count = count + 1\n",
    "\n",
    "# no missing data\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df367f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# calculate data for all events\n",
    "new_results = []\n",
    "for result in tqdm(results):\n",
    "    date = result['date']\n",
    "    ticker = result['ticker']\n",
    "    try:\n",
    "        # Get 2-day pre-event close price\n",
    "        price_data = get_two_days_before_event(financial_data, ticker, date)\n",
    "        result['mean_price_minus_2_day_close'] = price_data['Close'][ticker].mean()\n",
    "\n",
    "        # Extended days to include up to 60\n",
    "        day_list = [1, 7, 14, 21, 30, 38, 45, 53, 60]\n",
    "\n",
    "        # Get post-event close prices for each day in list\n",
    "        for day in day_list:\n",
    "            price_data = get_data_x_days_after_event(financial_data, ticker, date, day)\n",
    "            result[f'mean_price_plus_{day}_day_close'] = price_data.loc[price_data.index.max(), 'Close'][ticker]\n",
    "\n",
    "        # Calculate raw return ranges\n",
    "        for day in day_list:\n",
    "            result[f'{day}_day_range'] = (result[f'mean_price_plus_{day}_day_close'] - result['mean_price_minus_2_day_close']) / result['mean_price_minus_2_day_close']\n",
    "\n",
    "        # SPY comparisons (market-adjusted)\n",
    "        price_data = get_two_days_before_event(financial_data, \"SPY\", date)\n",
    "        result['mean_spy_price_minus_2_day_close'] = price_data['Close'][\"SPY\"].mean()\n",
    "\n",
    "        for day in day_list:\n",
    "            price_data = get_data_x_days_after_event(financial_data, \"SPY\", date, day)\n",
    "            result[f'mean_spy_price_plus_{day}_day_close'] = price_data.loc[price_data.index.max(), 'Close'][\"SPY\"]\n",
    "            result[f'{day}_day_spy_range'] = (result[f'mean_spy_price_plus_{day}_day_close'] - result['mean_spy_price_minus_2_day_close']) / result['mean_spy_price_minus_2_day_close']\n",
    "            result[f'adjusted_{day}_day_range'] = result[f'{day}_day_range'] - result[f'{day}_day_spy_range']\n",
    "\n",
    "        new_results.append(result)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Skip bad data points (e.g., delisted tickers, missing prices)\n",
    "        pass\n",
    "\n",
    "# convert to dataframe\n",
    "df = pd.DataFrame(new_results)\n",
    "\n",
    "# Extract the label and flatten the structure\n",
    "df['label'] = df['annotation_json'].apply(lambda x: x.get('label', 'Unknown'))\n",
    "df['adjusted_1_day_range'] = df['adjusted_1_day_range'].astype(float)\n",
    "\n",
    "# Apply to your DataFrame\n",
    "annotation_flat = df.apply(flatten_annotation, axis=1)\n",
    "\n",
    "# Merge back into the original dataframe (or just use `annotation_flat` as new base)\n",
    "df_expanded = pd.concat([df.drop(columns=['annotation_json']), annotation_flat], axis=1)\n",
    "\n",
    "# add the cap labels\n",
    "df_expanded[\"market_cap_label\"] = df_expanded[\"ticker\"].map(cap_classes)\n",
    "\n",
    "df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1497eef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# filter the dataset down to reporting clinical trial results\n",
    "data_for_annotation =  df_expanded[\n",
    "    (df_expanded.event_type.isin(['Reporting Results & Data', 'Preliminary or Interim Results Shared']))\n",
    "].copy()\n",
    "data_for_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f5b97",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# fetch the article text and add it to the table\n",
    "conn = sqlite3.connect(\"biotech_data.db\")\n",
    "conn.row_factory = sqlite3.Row\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query only article_id and article_text\n",
    "cursor.execute('''\n",
    "    SELECT \n",
    "        articles.id AS article_id,\n",
    "        articles.text AS article_text\n",
    "    FROM article_annotation\n",
    "    JOIN articles ON article_annotation.article_id = articles.id\n",
    "''')\n",
    "\n",
    "# Fetch results and convert to DataFrame\n",
    "rows = cursor.fetchall()\n",
    "article_text_df = pd.DataFrame([dict(row) for row in rows])\n",
    "\n",
    "# Drop duplicates in case of multiple annotations per article\n",
    "article_text_df = article_text_df.drop_duplicates(subset='article_id')\n",
    "data_for_annotation = data_for_annotation.merge(article_text_df, on='article_id', how='left')\n",
    "data_for_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8bd98",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using LLMs to extract additional features out of it\n",
    "\n",
    "new_annotations = []\n",
    "\n",
    "for x in tqdm(range(0, len(data_for_annotation))):\n",
    "    row = data_for_annotation.iloc[x]\n",
    "    article_text = row['article_text']\n",
    "\n",
    "    try:\n",
    "        # Prompt 1 – Tone, narrative, and IR framing\n",
    "        prompt_1 = f\"\"\"\n",
    "        You are analyzing a biotech press release to extract narrative style, tone, promotional framing, and signals of forward progress. Return a JSON object with the following fields:\n",
    "\n",
    "        {{\n",
    "          \"mentions_pipeline_expansion\": <true / false>,\n",
    "          \"mentions_lack_of_competitors\": <true / false>,\n",
    "          \"mentions_next_milestone\": <true / false>,\n",
    "          \"mentions_specific_timeline\": <true / false>,\n",
    "          \"timeline_confidence_score\": <number from 1 (vague or speculative) to 10 (specific and confident)>,\n",
    "          \"mentions_upcoming_data_readout\": <true / false>,\n",
    "          \"is_ir_tone_dominant\": <true / false>,\n",
    "          \"ir_tone_score\": <number from 1 (dry and technical, tailored for scientists) to 10 (promotional and tailored to investors)>,\n",
    "          \"uses_promotional_language\": <true / false>,\n",
    "          \"uses_fomo_language\": <true / false>,\n",
    "          \"narrative_style\": \"<Promotional / Technical / Strategic / Neutral>\",\n",
    "          \"mentions_market_impact\": <true / false>,\n",
    "          \"tone_score\": <number from 1 (dry and technical) to 10 (optimistic and promotional)>,\n",
    "          \"forward_looking_statements\": <true / false>,\n",
    "          \"hedging_score\": <number from 1 (no hedging) to 10 (high hedging language)>,\n",
    "          \"bullish_sentiment_score\": <number from 1 to 10>\n",
    "        }}\n",
    "\n",
    "        Press Release:\n",
    "        \\\"\\\"\\\"{article_text}\\\"\\\"\\\"\n",
    "        \"\"\"\n",
    "        result_1 = make_json_llm_call(client, prompt_1)\n",
    "\n",
    "        # Prompt 2 – Clinical outcomes & real-world relevance\n",
    "        prompt_2 = f\"\"\"\n",
    "        Analyze this biotech press release to extract structured clinical outcomes and real-world relevance. Return the following JSON object:\n",
    "\n",
    "        {{\n",
    "          \"mentions_statistical_significance\": <true / false>,\n",
    "          \"efficacy_percent_improvement\": <percentage or null>,\n",
    "          \"survival_rate_mentioned\": <true / false>,\n",
    "          \"outcome_significance_score\": <number from 1 (minor) to 10 (groundbreaking)>,\n",
    "          \"mentions_clinically_meaningful\": <true / false>,\n",
    "          \"mentions_quality_of_life_improvement\": <true / false>,\n",
    "          \"mentions_hospitalization_reduction\": <true / false>,\n",
    "          \"mentions_symptom_relief\": <true / false>,\n",
    "          \"mentions_real_world_relevance\": <true / false>,\n",
    "          \"mentions_durable_response\": <true / false>,\n",
    "          \"response_depth\": \"<Deep / Moderate / Minimal / Unknown>\",\n",
    "          \"mentions_response_in_subgroups\": <true / false>,\n",
    "          \"uses_vague_descriptors_only\": <true / false>,\n",
    "          \"confidence_language_score\": <number from 1 (highly uncertain, cautious tone) to 10 (very confident, assertive, and definitive tone)>,\n",
    "          \"mentions_adverse_events\": <true / false>,\n",
    "          \"safety_profile_summary\": \"<Well-tolerated / Mixed / Concerning>\"\n",
    "        }}\n",
    "\n",
    "        Press Release:\n",
    "        \\\"\\\"\\\"{article_text}\\\"\\\"\\\"\n",
    "        \"\"\"\n",
    "        result_2 = make_json_llm_call(client, prompt_2)\n",
    "\n",
    "        # Prompt 3 – Strategic signals\n",
    "        prompt_3 = f\"\"\"\n",
    "        You are analyzing a biotech press release for signs of strategic shifts, urgency, and internal business pressures. Extract the following structured signals and return the following fields as JSON. If a field is unclear, return null and DO NOT GUESS.\n",
    "\n",
    "        {{\n",
    "          \"mentions_funding_pressure\": <true / false>,\n",
    "          \"mentions_employee_changes_or_hiring\": <true / false>,\n",
    "          \"suggests_m_and_a_potential\": <true / false>,\n",
    "          \"mentions_strategic_review_or_business_model_shift\": <true / false>,\n",
    "          \"urgency_score\": <1–10>,\n",
    "          \"mentions_cost_cutting\": <true / false>,\n",
    "          \"mentions_pipeline_prioritization\": <true / false>\n",
    "        }}\n",
    "\n",
    "        Press Release:\n",
    "        \\\"\\\"\\\"{article_text}\\\"\\\"\\\"\n",
    "        \"\"\"\n",
    "        result_3 = make_json_llm_call(client, prompt_3)\n",
    "\n",
    "        # Prompt 4 – Commercial readiness\n",
    "        prompt_4 = f\"\"\"\n",
    "        You are analyzing a biotech press release for signs of commercial readiness and market entry planning. Extract the following fields as JSON. If a field is not applicable, return null.\n",
    "\n",
    "        {{\n",
    "          \"mentions_pre_launch_preparations\": <true / false>,\n",
    "          \"mentions_manufacturing_or_supply_chain\": <true / false>,\n",
    "          \"mentions_distribution_partners\": <true / false>,\n",
    "          \"mentions_sales_team_or_hiring\": <true / false>,\n",
    "          \"mentions_market_access_or_reimbursement\": <true / false>,\n",
    "          \"commercial_readiness_score\": <1 (no evidence) to 10 (extensively discussed)>\n",
    "        }}\n",
    "\n",
    "        Press Release:\n",
    "        \\\"\\\"\\\"{article_text}\\\"\\\"\\\"\n",
    "        \"\"\"\n",
    "        result_4 = make_json_llm_call(client, prompt_4)\n",
    "\n",
    "        # Prompt 5 – Audience targeting\n",
    "        prompt_5 = f\"\"\"\n",
    "        You are analyzing a biotech press release to understand who it is primarily written for and how it’s framed. Extract data from the attached press release and return JSON with the following structured information:\n",
    "\n",
    "        {{\n",
    "          \"primary_audience\": <\"investor\" | \"scientific\" | \"media/general public\" | \"regulatory\" | null>,\n",
    "          \"mentions_media_outlets_or_coverage\": <true / false>,\n",
    "          \"mentions_social_or_patient_engagement\": <true / false>,\n",
    "          \"includes_technical_figures_or_metrics\": <true / false>,\n",
    "          \"mentions_target_stock_exchange_or_index\": <true / false>,\n",
    "          \"language_alignment_with_regulators\": <true / false>\n",
    "        }}\n",
    "\n",
    "        Press Release:\n",
    "        \\\"\\\"\\\"{article_text}\\\"\\\"\\\"\n",
    "        \"\"\"\n",
    "        result_5 = make_json_llm_call(client, prompt_5)\n",
    "\n",
    "        # Prompt 6 – Trial design rigor\n",
    "        prompt_6 = f\"\"\"\n",
    "        You are analyzing a biotech press release for trial design features and study realism.Extract data from the attached press release and return JSON with the following structured information:\n",
    "\n",
    "        {{\n",
    "          \"mentions_adaptive_trial_design\": <true / false>,\n",
    "          \"mentions_placebo_or_comparator_arm\": <true / false>,\n",
    "          \"mentions_real_world_evidence\": <true / false>,\n",
    "          \"mentions_biomarker_selection\": <true / false>,\n",
    "          \"mentions_global_or_multicenter_scope\": <true / false>,\n",
    "          \"trial_design_rigor_score\": <1 (minimal rigor) to 10 (robust and methodologically strong)>\n",
    "        }}\n",
    "\n",
    "        Press Release:\n",
    "        \\\"\\\"\\\"{article_text}\\\"\\\"\\\"\n",
    "        \"\"\"\n",
    "        result_6 = make_json_llm_call(client, prompt_6)\n",
    "\n",
    "        # Prompt 7 – Novelty, credibility, confidence\n",
    "        prompt_7 = f\"\"\"\n",
    "        You are analyzing a biotech press release for subtle cues around market signaling, management confidence, novelty of the news, and credibility framing. Extract structured features as JSON using the definitions and value ranges provided.\n",
    "\n",
    "        {{\n",
    "          \"announcement_novelty_score\": <number from 1 (repeated or known) to 10 (entirely new and previously undisclosed)>,\n",
    "          \"mentions_previous_similar_announcements\": <true / false>,\n",
    "          \"mentions_prior_failure_or_setback\": <true / false>,\n",
    "          \"mentions_reversal_or_recovery\": <true / false>,\n",
    "          \"mentions_internal_confidence_measures\": <true / false>,\n",
    "          \"includes_third_party_validation\": <true / false>,\n",
    "          \"mentions_patient_advocacy_group_or_foundation\": <true / false>,\n",
    "          \"mentions_key_opinion_leader\": <true / false>,\n",
    "          \"novel_mechanism_of_action\": <true / false>,\n",
    "          \"competitive_differentiation_score\": <number from 1 (none mentioned) to 10 (strongly differentiated vs competitors)>,\n",
    "          \"mentions_market_opportunity_size\": <true / false>,\n",
    "          \"mentions_cost_effectiveness_or_pricing\": <true / false>,\n",
    "          \"language_indicating_management_confidence\": <true / false>,\n",
    "          \"mentions_risks_or_uncertainties\": <true / false>,\n",
    "          \"risk_disclosure_score\": <number from 1 (no mention of risk) to 10 (transparent, balanced discussion of risks)>,\n",
    "          \"overemphasized_positivity_score\": <number from 1 (very neutral and factual) to 10 (heavily embellished or spin-heavy)>\n",
    "        }}\n",
    "\n",
    "        Press Release:\n",
    "        \\\"\\\"\\\"{article_text}\\\"\\\"\\\"\n",
    "        \"\"\"\n",
    "        result_7 = make_json_llm_call(client, prompt_7)\n",
    "\n",
    "        # Merge all results\n",
    "        combined_result = {\n",
    "            **result_1,\n",
    "            **result_2,\n",
    "            **result_3,\n",
    "            **result_4,\n",
    "            **result_5,\n",
    "            **result_6,\n",
    "            **result_7,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Annotation failed on row {x}: {e}\")\n",
    "        combined_result = {}\n",
    "\n",
    "    new_annotations.append(combined_result)\n",
    "\n",
    "# Final merge\n",
    "annotations_df = pd.DataFrame(new_annotations)\n",
    "data_for_annotation = pd.concat([data_for_annotation.reset_index(drop=True), annotations_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4aa6d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# save data to .csv files\n",
    "data_for_annotation[data_for_annotation.result_type.isin(['Negative Results - Lack of Efficacy','Negative Results - Safety / Adverse Effect'])].to_csv(\"data/csv_files/negative_clinical_trial_results.csv\")\n",
    "data_for_annotation[data_for_annotation.result_type.isin(['Positive Results'])].to_csv(\"data/csv_files/positive_clinical_trial_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
